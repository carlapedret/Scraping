{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Scraping a Wikipedia table with ID</h3>\n",
    "<p>Tutorial:</p> \n",
    "https://medium.com/@sateesh.gmc/how-to-scrape-wikipedia-table-using-python-beautiful-soup-cd0d8ee1a319\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the variable with the url you want to screape\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_population_(United_Nations)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import de libraries you need. \n",
    "# First install them with conda\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Library for performing your HTTP requests to fetch web content\n",
    "import requests\n",
    "\n",
    "#Beautiful soup\n",
    "from bs4 import BeautifulSoup\n",
    "# To control the requests requests does\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>By default, Request will keep waiting for a response indefinitely. Therefore, it is advised to set the timeout parameter and also use requests. Sessions(), helps in initiating multiple url requests. If your request is successful, then expected HTTP response status code is 200. You may check Wikipedia reference — HTTP status codes — for important error codes like — 404 (Not Found), 403 (Forbidden), 408 (Request Timeout).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Requests and response\n",
    "s = requests.Session()\n",
    "response = s.get(url, timeout=10)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'List of countries by population (United Nations) - Wikipedia'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title of the page \n",
    "#soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = 'main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the columns as a CSV\n",
    "csvfile = open('population.csv', 'w')\n",
    "csvwriter = csv.writer(csvfile, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ('COUNTRY','CONTINENT','SUBREGION', 'POPULATION_2018', 'POPULATION_2019', 'CHANGE')\n",
    "csvwriter.writerow(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table', attrs={'id': table_id})\n",
    "for row in table.find_all('tr')[1:]:\n",
    "    col = row.find_all('td')\n",
    "    if col:\n",
    "        country = col[0].find('a').contents[0]\n",
    "        continent = col[1].string\n",
    "        subregion = col[2].string\n",
    "        population_2018 = col[3].string\n",
    "        population_2019 = col[4].string\n",
    "        change = col[5].find(text=True)\n",
    "    \n",
    "    parsed_row = (country, continent, subregion, population_2018, population_2019, change)\n",
    "    csvwriter.writerow(parsed_row)\n",
    "\n",
    "csvfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
